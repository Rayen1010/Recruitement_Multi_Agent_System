{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Any, TypedDict\n",
    "import os\n",
    "import urllib\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import yaml\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_ollama import OllamaLLM  \n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from langsmith import Client  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driver  \n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Driver:\n",
    "    def __init__(self, url, cookie=None):\n",
    "        self.driver = self._create_driver(url, cookie)\n",
    "\n",
    "    def navigate(self, url, wait=3):\n",
    "        self.driver.get(url)\n",
    "        time.sleep(wait)\n",
    "\n",
    "    def scroll_to_bottom(self, wait=3):\n",
    "        self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(wait)\n",
    "        self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(wait)\n",
    "\n",
    "    def get_element(self, selector):\n",
    "        return self.driver.find_element(By.CSS_SELECTOR, selector)\n",
    "\n",
    "    def get_elements(self, selector):\n",
    "        return self.driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "\n",
    "    def fill_text_field(self, selector, text):\n",
    "        element = self.get_element(selector)\n",
    "        element.clear()\n",
    "        element.send_keys(text)\n",
    "\n",
    "    def click_button(self, selector):\n",
    "        element = self.get_element(selector)\n",
    "        element.click()\n",
    "\n",
    "    def _create_driver(self, url, cookie):\n",
    "        options = Options()\n",
    "        # options.add_argument(\"--headless\")\n",
    "        driver = webdriver.Firefox(options=options)\n",
    "        driver.get(url)\n",
    "        if cookie:\n",
    "            driver.add_cookie(cookie)\n",
    "        return driver\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding People according to skills , through a LinkedinClient Page\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedinClient:\n",
    "    def __init__(self):\n",
    "        url = 'https://linkedin.com/'\n",
    "        cookie = {\n",
    "            \"name\": \"li_at\",\n",
    "            \"value\": os.environ.get(\"LINKEDIN_COOKIE\", \"\"),\n",
    "            \"domain\": \".linkedin.com\"\n",
    "        }\n",
    "\n",
    "        self.driver = Driver(url, cookie)\n",
    "\n",
    "    def find_people(self, skills):\n",
    "        skills = skills.split(\",\")\n",
    "        search = \" \".join(skills)\n",
    "        encoded_string = urllib.parse.quote(search.lower()) #Python%20Machine%20Learning for example\n",
    "        url = f\"https://www.linkedin.com/search/results/people/?keywords={encoded_string}\" #view People Cap Page Example\n",
    "        self.driver.navigate(url)\n",
    "\n",
    "        people = self.driver.get_elements(\"ul li div div.linked-area\") #selector provided after inspecting the page with url = url , People contains A list of Selenium WebElement objects , Typically 10 results per page\n",
    "\n",
    "        results = []\n",
    "        for person in people:\n",
    "            try:\n",
    "                result = {}\n",
    "                result[\"name\"] = person.find_element(By.CSS_SELECTOR, \"span.entity-result__title-line\").text\n",
    "                result[\"position\"] = person.find_element(By.CSS_SELECTOR, \"div.entity-result__primary-subtitle\").text\n",
    "                result[\"location\"] = person.find_element(By.CSS_SELECTOR, \"div.entity-result__secondary-subtitle\").text\n",
    "                result[\"profile_link\"] = person.find_element(By.CSS_SELECTOR, \"a.app-aware-link\").get_attribute(\"href\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            results.append(result)\n",
    "        return results\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "#Expected Output Example : \n",
    "# [  \n",
    "  #{  \n",
    "    #\"name\": \"John Doe\",  \n",
    "    #\"position\": \"Senior AI Engineer at Google\",  \n",
    "    #\"location\": \"San Francisco\",  \n",
    "    #\"profile_link\": \"https://linkedin.com/in/johndoe\"  \n",
    "  #},  \n",
    "  #...  \n",
    "#]         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linkedin search tool on top of the Driver and the LinkedinClient \n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkedin_search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for LinkedIn profiles based on skills.\n",
    "    \n",
    "    Args:\n",
    "        query: Comma-separated list of skills to search for\n",
    "        \n",
    "    Returns:\n",
    "        Formatted list of profiles found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        linkedin_client = LinkedinClient()\n",
    "        people = linkedin_client.find_people(query)\n",
    "        \n",
    "        result = [\"\\n\".join([\n",
    "            \"Person Profile\",\n",
    "            \"-------------\",\n",
    "            p['name'],\n",
    "            p['position'],\n",
    "            p['location'],\n",
    "            p[\"profile_link\"],\n",
    "        ]) for p in people]\n",
    "        \n",
    "        formatted_result = \"\\n\\n\".join(result)\n",
    "        linkedin_client.close()\n",
    "        return formatted_result\n",
    "    except Exception as e:\n",
    "        return f\"Error searching LinkedIn: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Search tool with Google search API wrapper \n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serper_search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the web using the SerperDev API.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        \n",
    "    Returns:\n",
    "        The search results as a string\n",
    "    \"\"\"\n",
    "    api_key = os.environ.get(\"SERPER_API_KEY\", \"\")\n",
    "    if not api_key:\n",
    "        return \"Error: SERPER_API_KEY environment variable not set\"\n",
    "    \n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    payload = json.dumps({\n",
    "        \"q\": query\n",
    "    })\n",
    "    headers = {\n",
    "        'X-API-KEY': api_key,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error performing search: {str(e)}\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_website_tool(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Scrape content from a website.\n",
    "    \n",
    "    Args:\n",
    "        url: The URL to scrape\n",
    "        \n",
    "    Returns:\n",
    "        The scraped content as a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        })\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error scraping website: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Scrape_website_tool and serper_search_tool \n",
    "--------------------\n",
    "\n",
    "Step 1: Use serper_search_tool to find candidate related websites lik github \n",
    "exmpl : results = serper_search_tool(\"Rayen Rust Developer site:github.com\")\n",
    "\n",
    "Step 2: Step 2: Feed discovered URLs to scrape_website_tool\n",
    "exmpl : github_html = scrape_website_tool(results[\"organic\"][0][\"link\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent Prompt And llms\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load agent configurations\n",
    "with open('config/agents.yaml', 'r') as file:\n",
    "    agents_config = yaml.safe_load(file)\n",
    "\n",
    "# Load task configurations\n",
    "with open('config/tasks.yaml', 'r') as file:\n",
    "    tasks_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: List[Dict[str, Any]]\n",
    "    researcher_output: Optional[str]\n",
    "    matcher_output: Optional[str]\n",
    "    communicator_output: Optional[str]\n",
    "    reporter_output: Optional[str]\n",
    "    current_agent: str\n",
    "    job_requirements: str\n",
    "\n",
    "#This state object is passed through each node in Langgraph enabling context, communication between agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent_prompt(role: str, goal: str, backstory: str, task_description: str) -> str:\n",
    "    \"\"\"Creates a prompt for an agent based on its role and task.\"\"\"\n",
    "    return f\"\"\"\n",
    "You are a {role}.\n",
    "Your goal is: {goal}\n",
    "Your backstory: {backstory}\n",
    "\n",
    "Your current task:\n",
    "{task_description}\n",
    "\n",
    "Respond with your findings and analysis. Be thorough but focus on delivering actionable insights.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_researcher_llm():\n",
    "    \"\"\"Create the researcher agent's LLM.\"\"\"\n",
    "    return OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matcher_llm():\n",
    "    \"\"\"Create the matcher agent's LLM.\"\"\"\n",
    "    return OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_communicator_llm():\n",
    "    \"\"\"Create the communicator agent's LLM.\"\"\"\n",
    "    return OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reporter_llm():\n",
    "    \"\"\"Create the reporter agent's LLM.\"\"\"\n",
    "    return OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes' Tools\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_tools = ToolNode(\n",
    "    tools=[\n",
    "        linkedin_search_tool,\n",
    "        serper_search_tool,\n",
    "        scrape_website_tool\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_tools = ToolNode(\n",
    "    tools=[\n",
    "        serper_search_tool,\n",
    "        scrape_website_tool\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "communicator_tools = ToolNode(\n",
    "    tools=[\n",
    "        serper_search_tool,\n",
    "        scrape_website_tool\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_agent(state: AgentState) -> Dict:\n",
    "    \"\"\"Researcher agent node function.\"\"\"\n",
    "    researcher_config = agents_config[\"researcher\"]\n",
    "    task_config = tasks_config[\"research_candidates_task\"]\n",
    "    \n",
    "    # Format the task description with job requirements\n",
    "    task_description = task_config[\"description\"].format(\n",
    "        job_requirements=state[\"job_requirements\"]\n",
    "    )\n",
    "    \n",
    "    # Create the prompt for the researcher\n",
    "    prompt = create_agent_prompt(\n",
    "        researcher_config[\"role\"],\n",
    "        researcher_config[\"goal\"],\n",
    "        researcher_config[\"backstory\"],\n",
    "        task_description\n",
    "    )\n",
    "    \n",
    "    \n",
    "    messages = state[\"messages\"] + [\n",
    "        HumanMessage(content=prompt)  #updating the messages \n",
    "    ]\n",
    "    \n",
    "    # Get response from the LLM\n",
    "    response = get_researcher_llm().invoke(messages)\n",
    "    \n",
    "    # Update the state with researcher's output\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            HumanMessage(content=prompt),\n",
    "            AIMessage(content=response)  \n",
    "        ],\n",
    "        \"researcher_output\": response,  \n",
    "        \"current_agent\": \"matcher\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matcher_agent(state: AgentState) -> Dict:\n",
    "    \"\"\"Matcher agent node function.\"\"\"\n",
    "    matcher_config = agents_config[\"matcher\"]\n",
    "    task_config = tasks_config[\"match_and_score_candidates_task\"]\n",
    "    \n",
    "    # Format the task description with job requirements\n",
    "    task_description = task_config[\"description\"].format(\n",
    "        job_requirements=state[\"job_requirements\"]\n",
    "    )\n",
    "    \n",
    "    # Create the prompt for the matcher\n",
    "    prompt = create_agent_prompt(\n",
    "        matcher_config[\"role\"],\n",
    "        matcher_config[\"goal\"],\n",
    "        matcher_config[\"backstory\"],\n",
    "        task_description\n",
    "    )\n",
    "    \n",
    "    # Add the researcher's output to the prompt\n",
    "    prompt += f\"\\n\\nResearcher's findings:\\n{state['researcher_output']}\"\n",
    "    \n",
    "    # Create the message for the LLM\n",
    "    messages = state[\"messages\"] + [\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "    \n",
    "    # Get response from the LLM\n",
    "    response = get_matcher_llm().invoke(messages)\n",
    "    \n",
    "    # Update the state with matcher's output\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            HumanMessage(content=prompt),\n",
    "            AIMessage(content=response)  # Use response directly\n",
    "        ],\n",
    "        \"matcher_output\": response,  # Use response directly\n",
    "        \"current_agent\": \"communicator\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communicator_agent(state: AgentState) -> Dict:\n",
    "    \"\"\"Communicator agent node function.\"\"\"\n",
    "    communicator_config = agents_config[\"communicator\"]\n",
    "    task_config = tasks_config[\"outreach_strategy_task\"]\n",
    "    \n",
    "    # Format the task description with job requirements\n",
    "    task_description = task_config[\"description\"].format(\n",
    "        job_requirements=state[\"job_requirements\"]\n",
    "    )\n",
    "    \n",
    "    # Create the prompt for the communicator\n",
    "    prompt = create_agent_prompt(\n",
    "        communicator_config[\"role\"],\n",
    "        communicator_config[\"goal\"],\n",
    "        communicator_config[\"backstory\"],\n",
    "        task_description\n",
    "    )\n",
    "    \n",
    "    # Add the matcher's output to the prompt\n",
    "    prompt += f\"\\n\\nScored and matched candidates:\\n{state['matcher_output']}\"\n",
    "    \n",
    "    # Create the message for the LLM\n",
    "    messages = state[\"messages\"] + [\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "    \n",
    "    # Get response from the LLM\n",
    "    response = get_communicator_llm().invoke(messages)\n",
    "    \n",
    "    # Update the state with communicator's output\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            HumanMessage(content=prompt),\n",
    "            AIMessage(content=response)  # Use response directly\n",
    "        ],\n",
    "        \"communicator_output\": response,  # Use response directly\n",
    "        \"current_agent\": \"reporter\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporter_agent(state: AgentState) -> Dict:\n",
    "    \"\"\"Reporter agent node function.\"\"\"\n",
    "    reporter_config = agents_config[\"reporter\"]\n",
    "    task_config = tasks_config[\"report_candidates_task\"]\n",
    "    \n",
    "    # Create the prompt for the reporter\n",
    "    prompt = create_agent_prompt(\n",
    "        reporter_config[\"role\"],\n",
    "        reporter_config[\"goal\"],\n",
    "        reporter_config[\"backstory\"],\n",
    "        task_config[\"description\"]\n",
    "    )\n",
    "    \n",
    "    # Add all previous outputs to the prompt\n",
    "    prompt += f\"\\n\\nResearcher's findings:\\n{state['researcher_output']}\"\n",
    "    prompt += f\"\\n\\nScored and matched candidates:\\n{state['matcher_output']}\"\n",
    "    prompt += f\"\\n\\nOutreach strategies:\\n{state['communicator_output']}\"\n",
    "    \n",
    "    # Create the message for the LLM\n",
    "    messages = state[\"messages\"] + [\n",
    "        HumanMessage(content=prompt) #eventhough it is a system message , but the humanmessage type Triggers the agent's \"response mode\" rather than \"continuation mode\"\n",
    "    ]\n",
    "    \n",
    "    # Get response from the LLM\n",
    "    response = get_reporter_llm().invoke(messages)\n",
    "    \n",
    "    # Format the final report as markdown\n",
    "    formatted_report = f\"\"\"\n",
    "# Recruitment Report: Best Candidates to Pursue\n",
    "\n",
    "## Top Candidates\n",
    "{state['matcher_output']}\n",
    "\n",
    "## Outreach Strategies\n",
    "{state['communicator_output']}\n",
    "\n",
    "## Detailed Profiles\n",
    "{state['researcher_output']}\n",
    "\"\"\"\n",
    "    \n",
    "    # Update the state with reporter's output\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            HumanMessage(content=prompt),\n",
    "            AIMessage(content=formatted_report)  \n",
    "        ],\n",
    "        \"reporter_output\": formatted_report,  \n",
    "        \"current_agent\": \"end\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Determines which agent should run next or if we should end.\"\"\"\n",
    "    current_agent = state[\"current_agent\"]\n",
    "    \n",
    "    if current_agent == \"researcher\":\n",
    "        if \"researcher_output\" in state and state[\"researcher_output\"]:\n",
    "            return \"matcher\"\n",
    "        return \"researcher\"\n",
    "    \n",
    "    elif current_agent == \"matcher\":\n",
    "        if \"matcher_output\" in state and state[\"matcher_output\"]:\n",
    "            return \"communicator\"\n",
    "        return \"matcher\"\n",
    "    \n",
    "    elif current_agent == \"communicator\":\n",
    "        if \"communicator_output\" in state and state[\"communicator_output\"]:\n",
    "            return \"reporter\"\n",
    "        return \"communicator\"\n",
    "    \n",
    "    elif current_agent == \"reporter\":\n",
    "        if \"reporter_output\" in state and state[\"reporter_output\"]:\n",
    "            return END\n",
    "        return \"reporter\"\n",
    "    \n",
    "    elif current_agent == \"end\":\n",
    "        return END\n",
    "    \n",
    "    return \"researcher\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recruitement Graph\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recruitment_graph() -> StateGraph:\n",
    "    \"\"\"Create the recruitment workflow graph.\"\"\"\n",
    "    \n",
    "    # Create the graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"researcher\", researcher_agent)\n",
    "    workflow.add_node(\"researcher_tools\", researcher_tools)\n",
    "    workflow.add_node(\"matcher\", matcher_agent)\n",
    "    workflow.add_node(\"matcher_tools\", matcher_tools)\n",
    "    workflow.add_node(\"communicator\", communicator_agent)\n",
    "    workflow.add_node(\"communicator_tools\", communicator_tools)\n",
    "    workflow.add_node(\"reporter\", reporter_agent)\n",
    "    \n",
    "    # Add edges - agent to tools\n",
    "    workflow.add_conditional_edges(\n",
    "        \"researcher\",\n",
    "        lambda state: \"researcher_tools\" if isinstance(state[\"messages\"][-1], ToolMessage) else should_continue(state)\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"matcher\",\n",
    "        lambda state: \"matcher_tools\" if isinstance(state[\"messages\"][-1], ToolMessage) else should_continue(state)\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"communicator\",\n",
    "        lambda state: \"communicator_tools\" if isinstance(state[\"messages\"][-1], ToolMessage) else should_continue(state)\n",
    "    )\n",
    "    \n",
    "    # Add edges - tools back to agents\n",
    "    workflow.add_edge(\"researcher_tools\", \"researcher\")\n",
    "    workflow.add_edge(\"matcher_tools\", \"matcher\")\n",
    "    workflow.add_edge(\"communicator_tools\", \"communicator\")\n",
    "    \n",
    "    # Add edges between agents\n",
    "    workflow.add_edge(\"researcher\" , \"matcher\")\n",
    "    workflow.add_edge(\"matcher\", \"communicator\")\n",
    "    workflow.add_edge(\"communicator\", \"reporter\")\n",
    "    \n",
    "    # Set the entry point\n",
    "    workflow.set_entry_point(\"researcher\")\n",
    "    \n",
    "    return workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Function \n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(job_requirements: str):\n",
    "    \"\"\"Run the recruitment workflow with the provided job requirements.\"\"\"\n",
    "    \n",
    "    # Create the graph\n",
    "    workflow = create_recruitment_graph()\n",
    "    \n",
    "    # Compile the graph\n",
    "    app = workflow.compile()\n",
    "    \n",
    "    # Initial state\n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"researcher_output\": None,\n",
    "        \"matcher_output\": None,\n",
    "        \"communicator_output\": None,\n",
    "        \"reporter_output\": None,\n",
    "        \"current_agent\": \"researcher\",\n",
    "        \"job_requirements\": job_requirements\n",
    "    }\n",
    "    \n",
    "    # Run the workflow\n",
    "    final_state = app.invoke(initial_state)\n",
    "    \n",
    "    # Return the final report\n",
    "    return final_state[\"reporter_output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function\n",
    "----------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Recruitment Report: Best Candidates to Pursue\n",
      "\n",
      "## Top Candidates\n",
      "Based on the research conducted by the Job Candidate Researcher, I will now evaluate and match the candidates to the best job positions based on their qualifications and suitability.\n",
      "\n",
      "**Candidate Matching:**\n",
      "\n",
      "1. **Ahmed M.**: Matches well with the \"Ruby on Rails and React Engineer\" position due to his extensive experience in Ruby on Rails and React development, as well as cloud services (AWS), Docker, and Kubernetes.\n",
      "\t* Score: 9/10\n",
      "2. **Kamel T.**: Also matches well with the position, demonstrating strong skills in backend development using Ruby on Rails and frontend development using React.\n",
      "\t* Score: 8.5/10\n",
      "3. **Amira B.**: Although she has expertise in full-stack development, her experience is not as extensive in Ruby on Rails and React development compared to Ahmed M. and Kamel T.\n",
      "\t* Score: 7.5/10\n",
      "4. **Léon J.**: Has some relevant experience in Ruby on Rails and React development, but his portfolio and GitHub profiles do not showcase the same level of expertise as Ahmed M. and Kamel T.\n",
      "\t* Score: 6.5/10\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "Based on the candidate matching scores, I recommend:\n",
      "\n",
      "1. **Hire Ahmed M.**: Due to his extensive experience in Ruby on Rails and React development, as well as cloud services (AWS), Docker, and Kubernetes, Ahmed M. is the top candidate for the position.\n",
      "2. **Invite Amira B. for a technical interview**: Although Amira B.'s skills are not as extensive as Ahmed M.'s, her experience in full-stack development could still be valuable to the team. Inviting her for an interview would allow for further assessment of her qualifications and suitability for the role.\n",
      "\n",
      "The other candidates, Kamel T. and Léon J., may still be considered for future opportunities or additional positions within the company, depending on their career goals and aspirations.\n",
      "\n",
      "## Outreach Strategies\n",
      "**Comprehensive Outreach Strategy for Selected Candidates**\n",
      "\n",
      "Based on the candidate matching scores and recommendations, I propose a comprehensive outreach strategy to engage Ahmed M., Amira B., Kamel T., and Léon J.\n",
      "\n",
      "**Strategy Overview:**\n",
      "\n",
      "1. **Personalized Email Campaigns**: Craft tailored email campaigns highlighting the unique value proposition of each candidate's skills and experience.\n",
      "2. **Social Media Outreach**: Utilize LinkedIn, Twitter, and other platforms to reach out to candidates, share company updates, and showcase job opportunities.\n",
      "3. **Phone or Video Interviews**: Schedule brief phone or video interviews with candidates to further assess their fit for the role and answer any questions they may have.\n",
      "\n",
      "**Email Campaign Templates:**\n",
      "\n",
      "1. **Ahmed M.**:\n",
      "\t* Subject Line: \"Unlock Your Potential as a Ruby on Rails and React Engineer\"\n",
      "\t* Body: \"We've reviewed your profile, and we're excited about your extensive experience in Ruby on Rails and React development. We believe you'd be an excellent fit for our team. Would you like to discuss the opportunity further?\"\n",
      "2. **Amira B.**:\n",
      "\t* Subject Line: \"Explore Full-Stack Development Opportunities at Our Company\"\n",
      "\t* Body: \"We've reviewed your profile, and we're interested in discussing how your full-stack development experience can contribute to our team's success. Would you like to schedule a brief call?\"\n",
      "3. **Kamel T.**:\n",
      "\t* Subject Line: \"Discover Your Passion for Ruby on Rails and React Development\"\n",
      "\t* Body: \"We've reviewed your profile, and we're excited about your skills in backend development using Ruby on Rails and frontend development using React. We'd love to discuss how you can join our team. Would you like to schedule a call?\"\n",
      "4. **Léon J.**:\n",
      "\t* Subject Line: \"Explore Development Opportunities with Our Company\"\n",
      "\t* Body: \"We've reviewed your profile, and we're interested in discussing how your experience in Ruby on Rails and React development can contribute to our team's growth. Would you like to schedule a brief call?\"\n",
      "\n",
      "**Social Media Outreach:**\n",
      "\n",
      "1. **LinkedIn**: Share company updates, job openings, and employee testimonials to showcase the company culture.\n",
      "2. **Twitter**: Utilize relevant hashtags (e.g., #RubyOnRails, #ReactJS) to reach a broader audience and share engaging content.\n",
      "\n",
      "**Phone or Video Interviews:**\n",
      "\n",
      "Schedule brief phone or video interviews with each candidate to:\n",
      "\n",
      "1. Answer questions about the role and company\n",
      "2. Assess their fit for the position\n",
      "3. Discuss any concerns or reservations they may have\n",
      "\n",
      "By implementing this comprehensive outreach strategy, we can increase the chances of attracting top talent for our Ruby on Rails and React Engineer position.\n",
      "\n",
      "## Detailed Profiles\n",
      "Based on the job requirements provided, I conducted a thorough research to find potential candidates for the Ruby on Rails and React Engineer position in Tunisia. Here are my findings and analysis:\n",
      "\n",
      "**Potential Candidates:**\n",
      "\n",
      "1. **Ahmed M.**: A Tunisian software engineer with 5+ years of experience in Ruby on Rails and React development. He has worked on several high-profile projects, including a e-commerce platform using Ruby on Rails and a mobile app using React Native. (LinkedIn Profile)\n",
      "2. **Amira B.**: A Tunisian full-stack developer with expertise in Ruby on Rails, React, and JavaScript. She has experience working with SQL and NoSQL databases, as well as code versioning tools like Git. (GitHub Profile)\n",
      "3. **Kamel T.**: A Tunisian software engineer with 7+ years of experience in backend development using Ruby on Rails, as well as frontend development using React. He has a strong understanding of object-oriented programming and is proficient in JavaScript, HTML, CSS, and React. (LinkedIn Profile)\n",
      "4. **Léon J.**: A Tunisian developer with 3+ years of experience in Ruby on Rails and React development. He has worked on several small-scale projects, including a blog using Ruby on Rails and a web app using React. (GitHub Profile)\n",
      "\n",
      "**Analysis:**\n",
      "\n",
      "* The top candidates all have relevant experience in Ruby on Rails and React development, which meets the job requirements.\n",
      "* Ahmed M. and Kamel T. stand out for their extensive experience with cloud services, Docker, and Kubernetes, which are preferred qualifications listed in the job description.\n",
      "* Amira B. and Léon J. demonstrate strong skills in frontend development using React, which is an essential requirement for this role.\n",
      "* All candidates have a strong understanding of object-oriented programming, JavaScript, HTML, CSS, and React, which are all required skills.\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "1. Reach out to Ahmed M. and Kamel T. directly to discuss their qualifications further, as they both meet the preferred qualifications listed in the job description.\n",
      "2. Invite Amira B. and Léon J. for a technical interview to assess their skills and experience in Ruby on Rails and React development.\n",
      "3. Review each candidate's portfolio and GitHub profiles to ensure that their work meets the job requirements.\n",
      "\n",
      "**Additional Insights:**\n",
      "\n",
      "* The Tunisian tech community is relatively small, which may limit the pool of potential candidates.\n",
      "* Networking with local developers and attending industry events could help identify more candidates who meet the job requirements.\n",
      "* Considering candidates from neighboring countries or regions may also be beneficial in identifying a diverse pool of talent.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Sample job requirements\n",
    "    job_requirements = \"\"\"\n",
    "    job_requirement:\n",
    "      title: >\n",
    "        Ruby on Rails and React Engineer\n",
    "      description: >\n",
    "        We are seeking a skilled Ruby on Rails and React engineer to join our team.\n",
    "        The ideal candidate will have experience in both backend and frontend development,\n",
    "        with a passion for building high-quality web applications , and lives in Tunisia ! .\n",
    "\n",
    "      responsibilities: >\n",
    "        - Develop and maintain web applications using Ruby on Rails and React.\n",
    "        - Collaborate with teams to define and implement new features.\n",
    "        - Write clean, maintainable, and efficient code.\n",
    "        - Ensure application performance and responsiveness.\n",
    "        - Identify and resolve bottlenecks and bugs.\n",
    "\n",
    "      requirements: >\n",
    "        - Proven experience with Ruby on Rails and React.\n",
    "        - Strong understanding of object-oriented programming.\n",
    "        - Proficiency with JavaScript, HTML, CSS, and React.\n",
    "        - Experience with SQL or NoSQL databases.\n",
    "        - Familiarity with code versioning tools, such as Git.\n",
    "\n",
    "      preferred_qualifications: >\n",
    "        - Experience with cloud services (AWS, Google Cloud, or Azure).\n",
    "        - Familiarity with Docker and Kubernetes.\n",
    "        - Knowledge of GraphQL.\n",
    "        - Bachelor's degree in Computer Science or a related field.\n",
    "\n",
    "      perks_and_benefits: >\n",
    "        - Competitive salary and bonuses.\n",
    "        - Health, dental, and vision insurance.\n",
    "        - Flexible working hours and remote work options.\n",
    "        - Professional development opportunities.\n",
    "    \"\"\"\n",
    "    \n",
    "    report = run(job_requirements)\n",
    "    print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama_based",
   "language": "python",
   "name": "ollama_based"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
